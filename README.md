Titanic - Exploratory Data Analysis

ğŸš€ Project Overview

This project is a comprehensive Exploratory Data Analysis (EDA) on the well-known Titanic dataset, designed to uncover insights about passenger survival rates based on various demographic and socio-economic features. With a clear focus on professionalism, problem-solving, and practical application, the project aims to explore patterns and relationships that influenced survival outcomes â€” insights crucial for building accurate predictive models.

In the latest version, the project has been enhanced with interactive visualizations, advanced data exploration techniques, and a robust logging system to ensure transparency, traceability, and maintainability of the analysis pipeline.

ğŸ¯ Project Goals
	â€¢	Data Cleaning & Preprocessing: Handle missing values, format data, and prepare it for analysis.
	â€¢	Statistical Analysis: Summarize key numerical and categorical features.
	â€¢	Exploratory Data Analysis (EDA): Identify patterns, trends, and relationships influencing survival rates.
	â€¢	Advanced Visualizations:
	â€¢	Static Visualizations: Histograms, box plots, and correlation heatmaps.
	â€¢	Interactive Visualizations: Dynamic charts for deeper insights and user engagement.
	â€¢	Logging System Implementation: Ensure detailed tracking of each processing step for full transparency.
	â€¢	Actionable Insights: Draw meaningful conclusions that could enhance predictive model performance.

ğŸ› ï¸ Tools & Libraries Used
	â€¢	Programming Language: ğŸ Python â€” Ideal for data analysis and machine learning projects.
	â€¢	Data Manipulation: pandas â€” For efficient data cleaning and transformation.
	â€¢	Numerical Operations: numpy â€” For array operations and mathematical functions.
	â€¢	Statistical Analysis: seaborn â€” For creating informative statistical visualizations.
	â€¢	Data Visualization:
	â€¢	matplotlib â€” For static visualizations like histograms and heatmaps.
	â€¢	plotly â€” For interactive, drill-down charts that enhance user experience.
	â€¢	Logging: logging â€” Tracks key processing steps, aiding in debugging and transparency.
	â€¢	Containerization: Docker â€” Ensures a consistent development and deployment environment.

ğŸ—‚ Dataset Description

The Titanic dataset contains information on passengers aboard the Titanic, including:

Feature	Description
PassengerId	Unique ID for each passenger
Survived	Survival status (0 = No, 1 = Yes)
Pclass	Ticket class (1st, 2nd, 3rd)
Name	Passengerâ€™s full name
Sex	Gender
Age	Age of the passenger
SibSp	# of siblings/spouses aboard
Parch	# of parents/children aboard
Ticket	Ticket number
Fare	Ticket fare
Cabin	Cabin number
Embarked	Port of embarkation

ğŸ“ˆ Steps Taken in the Project

1ï¸âƒ£ Data Loading:
	â€¢	Load and inspect the raw dataset from data/raw/.

2ï¸âƒ£ Data Cleaning & Preprocessing:
	â€¢	Handle missing values (Age, Cabin, Embarked).
	â€¢	Transform categorical data for consistency and usability.
	â€¢	Save the cleaned dataset in data/cleaned_data/cleaned_data.csv.

3ï¸âƒ£ Exploratory Data Analysis (EDA):
	â€¢	Generate descriptive statistics.
	â€¢	Analyze survival rates across different passenger classes, genders, and age groups.
	â€¢	Perform correlation analysis to assess feature relationships.

4ï¸âƒ£ Advanced Data Visualization:
	â€¢	Static Visualizations: Boxplots, heatmaps, and survival rate charts.
	â€¢	Interactive Visualizations:
	â€¢	interactive_distribution_of_age.html â€” Age distribution analysis.
	â€¢	interactive_survival_rate_by_pclass.html â€” Survival rate by class.
	â€¢	interactive_survival_rate_by_sex.html â€” Survival rate by gender.

5ï¸âƒ£ Logging Implementation:
	â€¢	Logs every critical step (data loading, cleaning, analysis, and visualization).
	â€¢	Logs stored in logs/ for traceability and debugging.

6ï¸âƒ£ Containerization (Optional):
	â€¢	Dockerfile provided for seamless deployment and consistent environments.

ğŸ— Folder Structure

Titanic-Exploratory-Data-Analysis/
â”‚
â”œâ”€â”€ data/                          # Dataset folder
â”‚   â”œâ”€â”€ raw/                       # Raw dataset
â”‚   â”œâ”€â”€ cleaned_data/              # Cleaned and preprocessed data
â”‚
â”œâ”€â”€ results/                       # Analysis and visual results
â”‚   â”œâ”€â”€ charts/                    # Static and interactive visualizations
â”‚   â”œâ”€â”€ summary_statistics.txt     # Key data insights and analysis results
â”‚
â”œâ”€â”€ scripts/                       # Python scripts for modular functionality
â”‚   â”œâ”€â”€ data_processing.py         # Data cleaning and preparation
â”‚   â”œâ”€â”€ analysis.py                # Exploratory data analysis
â”‚   â”œâ”€â”€ visualization.py           # Static and interactive visualizations
â”‚
â”œâ”€â”€ logs/                          # Logs for debugging and process tracking
â”‚
â”œâ”€â”€ Dockerfile                     # Containerization configuration
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ main.py                        # Main entry point for the project
â””â”€â”€ README.md                      # Project documentation

â–¶ï¸ How to Run the Project

1ï¸âƒ£ Clone the Repository:

git clone https://github.com/erenaktuerk/Titanic-Exploratory-Data-Analysis.git

2ï¸âƒ£ Navigate to the Project Directory:

cd Titanic-Exploratory-Data-Analysis

3ï¸âƒ£ Install Dependencies:

pip install -r requirements.txt

4ï¸âƒ£ Run the Main Script:

python main.py

5ï¸âƒ£ (Optional) Run with Docker:

docker build -t titanic-eda .
docker run -p 8050:8050 titanic-eda

ğŸŒ Interactive Visualizations

Once the project runs successfully, you can explore interactive charts stored in the results/charts/ folder by opening .html files directly in your browser.

ğŸ“ Future Improvements
	â€¢	Advanced Feature Engineering for more robust survival predictions.
	â€¢	Machine Learning Model Integration to predict survival based on explored insights.
	â€¢	Deployment of an Interactive Dashboard using frameworks like Dash or Streamlit.

ğŸ’¡ Key Takeaways
	â€¢	Enhanced Analytical Depth: Through advanced visualizations and exploratory techniques.
	â€¢	Improved Transparency: By implementing a well-structured logging system.
	â€¢	Real-World Relevance: Gained actionable insights that can inform future survival prediction models.

Letâ€™s take Titanic EDA to the next level! ğŸš¢ğŸ’¡